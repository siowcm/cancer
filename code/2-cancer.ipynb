{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324598b6-184a-4cdb-a89c-42b537f93dc2",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/siowcm/cancer/blob/main/code/02-cancer.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01079716-bb63-4f39-83b8-eacab1fdeb7b",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a8dfe3-4921-4ab5-92fd-c4af1086c39c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T05:42:59.722970Z",
     "iopub.status.busy": "2022-03-15T05:42:59.722451Z",
     "iopub.status.idle": "2022-03-15T05:43:05.694354Z",
     "shell.execute_reply": "2022-03-15T05:43:05.694109Z",
     "shell.execute_reply.started": "2022-03-15T05:42:59.722890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from imutils import paths\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d48d6-69e4-4313-b8c1-75772446b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone github repo\n",
    "!git clone https://github.com/siowcm/cancer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15bc9a-3bf9-443a-b7c5-1474ec4aab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./cancer/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef43e9b-80f6-49e2-a05b-bca11a8f9fed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:21:31.082561Z",
     "iopub.status.busy": "2022-03-15T01:21:31.082474Z",
     "iopub.status.idle": "2022-03-15T01:21:31.448907Z",
     "shell.execute_reply": "2022-03-15T01:21:31.448613Z",
     "shell.execute_reply.started": "2022-03-15T01:21:31.082552Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccabca75-81d0-4a6f-8688-88431ab800e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:21:31.449455Z",
     "iopub.status.busy": "2022-03-15T01:21:31.449378Z",
     "iopub.status.idle": "2022-03-15T01:21:31.499681Z",
     "shell.execute_reply": "2022-03-15T01:21:31.499437Z",
     "shell.execute_reply.started": "2022-03-15T01:21:31.449445Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 277524 entries, 0 to 277523\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   patient_id  277524 non-null  int64 \n",
      " 1   label       277524 non-null  int64 \n",
      " 2   path        277524 non-null  object\n",
      " 3   file_name   277524 non-null  object\n",
      " 4   img_x       277524 non-null  int64 \n",
      " 5   img_y       277524 non-null  int64 \n",
      " 6   height      277524 non-null  int64 \n",
      " 7   width       277524 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 16.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745c8cb-b5ea-4e74-9264-d43847141343",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0d1a0d-f876-4671-bee3-84ba23d2255f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:21:31.500833Z",
     "iopub.status.busy": "2022-03-15T01:21:31.500731Z",
     "iopub.status.idle": "2022-03-15T01:21:31.503535Z",
     "shell.execute_reply": "2022-03-15T01:21:31.503248Z",
     "shell.execute_reply.started": "2022-03-15T01:21:31.500820Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "TRAIN_PATH = \"../data/train\"\n",
    "VAL_PATH = \"../data/val\"\n",
    "TEST_PATH = \"../data/test\"\n",
    "IMG_SIZE = (48, 48)\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 10\n",
    "NUM_EPOCHS = 50\n",
    "INIT_LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6550620f-0d10-4d35-99d6-97f91e97558f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:21:31.504065Z",
     "iopub.status.busy": "2022-03-15T01:21:31.503999Z",
     "iopub.status.idle": "2022-03-15T01:21:31.603667Z",
     "shell.execute_reply": "2022-03-15T01:21:31.603416Z",
     "shell.execute_reply.started": "2022-03-15T01:21:31.504056Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create training, validation and testing data\n",
    "df_train_and_val, df_test = train_test_split(\n",
    "    df,\n",
    "    train_size=0.8,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "df_train, df_val = train_test_split(\n",
    "    df_train_and_val,\n",
    "    train_size=0.8,\n",
    "    random_state=42,\n",
    "    stratify=df_train_and_val[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5b7531-e570-42eb-a482-f51595497f05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:21:31.604358Z",
     "iopub.status.busy": "2022-03-15T01:21:31.604282Z",
     "iopub.status.idle": "2022-03-15T01:21:31.607497Z",
     "shell.execute_reply": "2022-03-15T01:21:31.607047Z",
     "shell.execute_reply.started": "2022-03-15T01:21:31.604348Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training df: (177615, 8)\n",
      "Shape of validation df: (44404, 8)\n",
      "Shape of testing df: (55505, 8)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of training and testing data\n",
    "print(f\"Shape of training df: {df_train.shape}\")\n",
    "print(f\"Shape of validation df: {df_val.shape}\")\n",
    "print(f\"Shape of testing df: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0da753b-b8c9-423d-b6b1-f03a38e76b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:21:31.608039Z",
     "iopub.status.busy": "2022-03-15T01:21:31.607965Z",
     "iopub.status.idle": "2022-03-15T01:21:31.611343Z",
     "shell.execute_reply": "2022-03-15T01:21:31.611080Z",
     "shell.execute_reply.started": "2022-03-15T01:21:31.608030Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create folder/ subfolders if it does not exist\n",
    "for folder in [TRAIN_PATH, VAL_PATH, TEST_PATH]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    if not os.path.exists(os.path.join(folder, \"0\")):\n",
    "        os.makedirs(os.path.join(folder, \"0\"))\n",
    "    if not os.path.exists(os.path.join(folder, \"1\")):\n",
    "        os.makedirs(os.path.join(folder, \"1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66f7e14d-2579-42db-94b0-5f5dc657a8bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:21:31.611926Z",
     "iopub.status.busy": "2022-03-15T01:21:31.611850Z",
     "iopub.status.idle": "2022-03-15T01:24:03.396104Z",
     "shell.execute_reply": "2022-03-15T01:24:03.392778Z",
     "shell.execute_reply.started": "2022-03-15T01:21:31.611917Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#copy to newly created folders\n",
    "for index, data in df_train.iterrows():\n",
    "    shutil.copy2(\n",
    "        data[\"path\"], os.path.join(TRAIN_PATH, str(data[\"label\"]))\n",
    "    )\n",
    "    \n",
    "for index, data in df_val.iterrows():\n",
    "    shutil.copy2(\n",
    "        data[\"path\"], os.path.join(VAL_PATH, str(data[\"label\"]))\n",
    "    )\n",
    "    \n",
    "for index, data in df_test.iterrows():\n",
    "    shutil.copy2(\n",
    "        data[\"path\"], os.path.join(TEST_PATH, str(data[\"label\"]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64226468-370c-49b3-888d-55f8a6d26a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:24:03.409978Z",
     "iopub.status.busy": "2022-03-15T01:24:03.409422Z",
     "iopub.status.idle": "2022-03-15T01:24:10.285632Z",
     "shell.execute_reply": "2022-03-15T01:24:10.285301Z",
     "shell.execute_reply.started": "2022-03-15T01:24:03.409869Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[01;34marchive\u001b[0m  [280 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mtest\u001b[0m\n",
      "│   ├── \u001b[01;34m0\u001b[0m  [39748 entries exceeds filelimit, not opening dir]\n",
      "│   └── \u001b[01;34m1\u001b[0m  [15757 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mtrain\u001b[0m\n",
      "│   ├── \u001b[01;34m0\u001b[0m  [127192 entries exceeds filelimit, not opening dir]\n",
      "│   └── \u001b[01;34m1\u001b[0m  [50423 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mval\u001b[0m\n",
      "│   ├── \u001b[01;34m0\u001b[0m  [31798 entries exceeds filelimit, not opening dir]\n",
      "│   └── \u001b[01;34m1\u001b[0m  [12606 entries exceeds filelimit, not opening dir]\n",
      "└── \u001b[00mcancer.csv\u001b[0m\n",
      "\n",
      "10 directories, 1 file\n"
     ]
    }
   ],
   "source": [
    "# check folder structure\n",
    "!apt-get install tree\n",
    "!cd ../data ; tree --dirsfirst --filelimit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "736aa4c2-84f1-460a-9850-bd6fb718fa04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:24:10.286327Z",
     "iopub.status.busy": "2022-03-15T01:24:10.286251Z",
     "iopub.status.idle": "2022-03-15T01:24:10.292412Z",
     "shell.execute_reply": "2022-03-15T01:24:10.292175Z",
     "shell.execute_reply.started": "2022-03-15T01:24:10.286316Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to load image\n",
    "def image_loader(path):\n",
    "    image = tf.io.read_file(path)                                # read image file as binary\n",
    "    image = tf.image.decode_png(image, channels=3)               # decode into image tensor\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)# converts to float32 data type and scaling the values appropriately before casting.\n",
    "    image = tf.image.resize(image, IMG_SIZE)                     # resize the image\n",
    "    label = tf.strings.split(path, os.path.sep)[-2]              # parse the class label from the file path\n",
    "    label = tf.strings.to_number(label, tf.int32)\n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46f66d4e-d66f-4dd7-a378-2eefcf978427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:28:40.211873Z",
     "iopub.status.busy": "2022-03-15T01:28:40.210797Z",
     "iopub.status.idle": "2022-03-15T01:28:40.226302Z",
     "shell.execute_reply": "2022-03-15T01:28:40.225540Z",
     "shell.execute_reply.started": "2022-03-15T01:28:40.211791Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to augment images\n",
    "@tf.function                                        #decarator code to create Python-independent dataflow graphs out of your Python code. \n",
    "def augmentation(image, label):                     #This will help you create performant and portable model.\n",
    "    image = tf.image.random_flip_left_right(image)  #random horizontal flips\n",
    "    image = tf.image.random_flip_up_down(image)     #random horizontal flips\n",
    "    return (image, label)                           #more augmenetation from tensorflow API https://www.tensorflow.org/api_docs/python/tf/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a07b2b72-cd43-4566-9374-43c07df4853b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:24:10.305260Z",
     "iopub.status.busy": "2022-03-15T01:24:10.305179Z",
     "iopub.status.idle": "2022-03-15T01:24:11.065934Z",
     "shell.execute_reply": "2022-03-15T01:24:11.065714Z",
     "shell.execute_reply.started": "2022-03-15T01:24:10.305250Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/train/0/14079_idx5_x2151_y1401_class0.png', '../data/train/0/14157_idx5_x1651_y301_class0.png']\n",
      "['../data/val/0/15510_idx5_x1801_y1001_class0.png', '../data/val/0/10295_idx5_x801_y951_class0.png']\n",
      "['../data/test/0/12749_idx5_x1451_y701_class0.png', '../data/test/0/8867_idx5_x2501_y1301_class0.png']\n"
     ]
    }
   ],
   "source": [
    "#create list pf images paths\n",
    "train_paths = list(paths.list_images(TRAIN_PATH))\n",
    "val_paths = list(paths.list_images(VAL_PATH))\n",
    "test_paths = list(paths.list_images(TEST_PATH))\n",
    "\n",
    "#print output for clarity \n",
    "print(train_paths[:2])\n",
    "print(val_paths[:2])\n",
    "print(test_paths[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "365812fe-5677-4cca-b9ab-63307ac41f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:24:11.066503Z",
     "iopub.status.busy": "2022-03-15T01:24:11.066429Z",
     "iopub.status.idle": "2022-03-15T01:24:11.134016Z",
     "shell.execute_reply": "2022-03-15T01:24:11.133737Z",
     "shell.execute_reply.started": "2022-03-15T01:24:11.066493Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights: {0: 1.0, 1: 2.5224996}\n"
     ]
    }
   ],
   "source": [
    "#create class weights\n",
    "train_labels = [int(p.split(os.path.sep)[-2]) for p in train_paths]\n",
    "train_labels = keras.utils.to_categorical(train_labels)              #one-hot encode list into arrary \n",
    "class_totals = train_labels.sum(axis=0)\n",
    "class_weight = {}\n",
    "for i in range(0, len(class_totals)):\n",
    "    class_weight[i] = class_totals.max() / class_totals[i]\n",
    "print(f\"class weights: {class_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ebb38b57-f00d-42ae-9b10-535c40b79e0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T01:37:19.816436Z",
     "iopub.status.busy": "2022-03-15T01:37:19.815930Z",
     "iopub.status.idle": "2022-03-15T01:37:19.886803Z",
     "shell.execute_reply": "2022-03-15T01:37:19.886472Z",
     "shell.execute_reply.started": "2022-03-15T01:37:19.816386Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Consider using this block of code for more fancify augmentatin from keras API\n",
    "https://keras.io/api/layers/preprocessing_layers/image_augmentation/\n",
    "'''\n",
    "\n",
    "# data_augmentation = tf.keras.Sequential(\n",
    "#     [\n",
    "#         keras.layers.RandomCrop(height, width, seed=None, **kwargs),\n",
    "#         keras.layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=None, **kwargs)\n",
    "#         keras.layers.RandomTranslation()\n",
    "#.        keras.layers.Rotation(),\n",
    "#         keras.layers.Zoom(),\n",
    "#         keras.layers.Contrast()\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# train_data = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "# train_data = (                         \n",
    "#     train_data.shuffle(len(train_paths))                                               # shuffle data, optional as already did train_test_split in scikit-learn\n",
    "#     .map(image_loader, num_parallel_calls=tf.data.AUTOTUNE)                            # load the image\n",
    "#     .map(augmentation, num_parallel_calls=tf.data.AUTOTUNE)                            # apply augmentation\n",
    "#     .map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE)  # augementation via Keras API}\n",
    "#     .cache()                                                                           # caching for fast read\n",
    "#     .batch(batch_size=BATCH_SIZE)                                                      # batching the data\n",
    "#     .prefetch(tf.data.AUTOTUNE)                                                        # allows later elements to be prepared while the current element is being processed\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b02a44-07b2-40eb-a407-8e75a6df8b76",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_data = (\n",
    "    train_data.shuffle(len(train_paths))                     # shuffle data, optional as already did train_test_split in scikit-learn\n",
    "    .map(image_loader, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .map(augmentation, num_parallel_calls=tf.data.AUTOTUNE)  # apply augmentation\n",
    "    .cache()                                                 # caching for fast read\n",
    "    .batch(batch_size=BATCH_SIZE)                            # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                              # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices(val_paths)              #no augmentation & shuffle required for test data as it is ground truth\n",
    "val_data = (\n",
    "    val_data.map(image_loader, num_parallel_calls=tf.data.AUTOTUNE)   # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                     # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                       # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(train_paths)           #no augmentation & shuffle required for test data as it is ground truth\n",
    "test_data = (\n",
    "    test_data.map(image_loader, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                     # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                       # allows later elements to be prepared while the current element is being processed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ebadb6-362c-415f-bfc1-4546d2fe899e",
   "metadata": {},
   "source": [
    "# Simple CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b4030-80e0-4f16-a3ed-75b6ee7931b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_cnn = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Conv2D(\n",
    "            filters=10,\n",
    "            kernel_size=3,\n",
    "            activation=\"relu\",\n",
    "            input_shape=(48, 48, 3),\n",
    "        ),\n",
    "        keras.layers.Conv2D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "        keras.layers.MaxPool2D(pool_size=2, padding=\"valid\"),\n",
    "        keras.layers.Conv2D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "        keras.layers.Conv2D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "        keras.layers.MaxPool2D(pool_size=2, padding=\"valid\"),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e5432-02a7-499a-b8b3-c5a249ec33fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b410011-58fc-44d6-a76f-52fcbec61dba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compile_fit_model(model, save_path):\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=INIT_LR),\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(),\n",
    "            keras.metrics.AUC(),\n",
    "            keras.metrics.Precision(),\n",
    "            keras.metrics.Recall(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    callbacks_list = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=PATIENCE,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(filepath=save_path, save_best_only=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        x=train_data,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        callbacks= callbacks_list,\n",
    "        validation_data=val_data,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2708f81-36ce-4416-977f-968d5f7efeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn, model_cnn = compile_fit_model(model=model_cnn, save_path=\"cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7852139-cfa6-42a8-bc6d-cd2d9816bd5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_cnn.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d9bd4-4072-4ce7-a8df-713fd3e80e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_cnn = pd.DataFrame(history_cnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f833e-8f91-4bf7-b8ea-a48bab2d7f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_cnn.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852eb2d6-e9a6-4d49-b72b-75737aae0bc2",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "In this section, the models will be built by using the convolution network of the pre-trained model (e.g. VGG16) as a backbone to extract features and add a fully-connected layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c7c467-ab46-47da-90e6-96b98a9161a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd244b8-7d39-439d-b9e1-9875900841e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to load image\n",
    "def image_loader_vgg16(path):\n",
    "    image = tf.io.read_file(path)                                # read image file as binary\n",
    "    image = tf.image.decode_png(image, channels=3)               # decode into image tensor\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)# converts to float32 data type and scaling the values appropriately before casting.\n",
    "    image = tf.image.resize(image, IMG_SIZE)                     # resize the image\n",
    "    image = keras.applications.vgg16.preprocess_input(image)     # custom preprocessing for VGG16\n",
    "    label = tf.strings.split(path, os.path.sep)[-2]              # parse the class label from the file path\n",
    "    label = tf.strings.to_number(label, tf.int32)\n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c3281-b319-4cd9-8117-0f9ae5216720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_data = (\n",
    "    train_data.shuffle(len(train_paths))                           # shuffle data, optional as already did train_test_split in scikit-learn\n",
    "    .map(image_loader_vgg16, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .map(augmentation, num_parallel_calls=tf.data.AUTOTUNE)        # apply augmentation\n",
    "    .cache()                                                       # caching for fast read\n",
    "    .batch(batch_size=BATCH_SIZE)                                  # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                    # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices(val_paths)                    #no augmentation & shuffle required for test data as it is ground truth\n",
    "val_data = (\n",
    "    val_data.map(image_loader_vgg16, num_parallel_calls=tf.data.AUTOTUNE)   # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                           # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                             # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(train_paths)                 #no augmentation & shuffle required for test data as it is ground truth\n",
    "test_data = (\n",
    "    test_data.map(image_loader_vgg16, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                           # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                             # allows later elements to be prepared while the current element is being processed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f6a79-fb00-4244-a371-58c3d9b06563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VGG16 = keras.applications.VGG16(include_top=False,weights=\"imagenet\")\n",
    "VGG16.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a301dfb-38b2-408c-ba68-6979d0476242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_vgg16 = keras.models.Sequential(\n",
    "    [\n",
    "        VGG16,\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29356df4-bff7-4705-a57d-1ed6e2f0b1f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f26f6-738d-4fca-ab0c-0fad946cab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vgg16, model_vgg16 = compile_fit_model(model=model_vgg16, save_path=\"vgg16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab750e-5170-4b86-816e-5a398850e975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_vgg16.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb507d-c9e6-4cd4-b2fd-f5435c398817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_vgg16 = pd.DataFrame(history_vgg16.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37061da-60ad-4ffe-a420-195a40ba1d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_vgg16.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a2cf8-7437-4def-b906-aacf9405b2eb",
   "metadata": {},
   "source": [
    "## EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea4b28-f345-400e-8130-cec74da89058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to load image\n",
    "def image_loader_effnetb0(path):\n",
    "    image = tf.io.read_file(path)                                # read image file as binary\n",
    "    image = tf.image.decode_png(image, channels=3)               # decode into image tensor\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)# converts to float32 data type and scaling the values appropriately before casting.\n",
    "    image = tf.image.resize(image, IMG_SIZE)                     # resize the image\n",
    "    image = keras.applications.efficientnet.preprocess_input(image)     # custom preprocessing for efficientnet\n",
    "    label = tf.strings.split(path, os.path.sep)[-2]              # parse the class label from the file path\n",
    "    label = tf.strings.to_number(label, tf.int32)\n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d340bee-685d-43c2-af0b-04b1d03adf15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_data = (\n",
    "    train_data.shuffle(len(train_paths))                           # shuffle data, optional as already did train_test_split in scikit-learn\n",
    "    .map(image_loader_effnetb0, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .map(augmentation, num_parallel_calls=tf.data.AUTOTUNE)        # apply augmentation\n",
    "    .cache()                                                       # caching for fast read\n",
    "    .batch(batch_size=BATCH_SIZE)                                  # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                    # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices(val_paths)                    #no augmentation & shuffle required for test data as it is ground truth\n",
    "val_data = (\n",
    "    val_data.map(image_loader_effnetb0, num_parallel_calls=tf.data.AUTOTUNE)   # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                           # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                             # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(train_paths)                 #no augmentation & shuffle required for test data as it is ground truth\n",
    "test_data = (\n",
    "    test_data.map(image_loader_effnetb0, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                           # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                             # allows later elements to be prepared while the current element is being processed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a42b1-dc66-4d8e-8293-099118a5ca06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "effnetb0 = keras.applications.EfficientNetB0(include_top=False,weights=\"imagenet\")\n",
    "effnetb0.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5b07c-a6dc-438b-87cb-b7c34bf0ba37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_effnetb0 = keras.models.Sequential(\n",
    "    [\n",
    "        effnetb0,\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b602af-0396-4350-9d27-f43f955c87f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_effnetb0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06efbfab-a907-4e4b-9799-fe23a31170e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_effnetb0, model_effnetb0 = compile_fit_model(model=model_effnetb0, save_path=\"effnetb0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf3032-c237-4f65-99d4-c69433d06c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_effnetb0.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e5a9e-d802-41a0-8311-5a0ef92aa467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_effnetb0 = pd.DataFrame(history_effnetb0.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13432af-f01a-41c2-bc3b-59e593eaaa91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_effnetb0.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deca209-dfa8-42f3-b152-d39c3fff84d8",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f9182c-2918-47b7-b212-d122a49dddf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to load image\n",
    "def image_loader_xception(path):\n",
    "    image = tf.io.read_file(path)                                # read image file as binary\n",
    "    image = tf.image.decode_png(image, channels=3)               # decode into image tensor\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)# converts to float32 data type and scaling the values appropriately before casting.\n",
    "    image = tf.image.resize(image, IMG_SIZE)                     # resize the image\n",
    "    image = keras.applications.xception.preprocess_input(image)     # custom preprocessing for xception\n",
    "    label = tf.strings.split(path, os.path.sep)[-2]              # parse the class label from the file path\n",
    "    label = tf.strings.to_number(label, tf.int32)\n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cca5c-6c45-4232-a1ce-41cde72c2512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_data = (\n",
    "    train_data.shuffle(len(train_paths))                           # shuffle data, optional as already did train_test_split in scikit-learn\n",
    "    .map(image_loader_xception, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .map(augmentation, num_parallel_calls=tf.data.AUTOTUNE)        # apply augmentation\n",
    "    .cache()                                                       # caching for fast read\n",
    "    .batch(batch_size=BATCH_SIZE)                                  # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                    # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices(val_paths)                    #no augmentation & shuffle required for test data as it is ground truth\n",
    "val_data = (\n",
    "    val_data.map(image_loader_xception, num_parallel_calls=tf.data.AUTOTUNE)   # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                           # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                             # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(train_paths)                 #no augmentation & shuffle required for test data as it is ground truth\n",
    "test_data = (\n",
    "    test_data.map(image_loader_xception, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                           # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                             # allows later elements to be prepared while the current element is being processed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e240e-55db-4a61-8700-c6a96c7c4125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xception = keras.applications.Xception(include_top=False,weights=\"imagenet\")\n",
    "xception.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f412c458-91ed-4e51-8a6b-0c6fec077cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_xception = keras.models.Sequential(\n",
    "    [\n",
    "        xception,\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4c2a3-b0bc-4993-9a50-5d6f869d288d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e1c7d-087b-470d-9f4e-7f967f87f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_xception, model_xception = compile_fit_model(model=model_xception, save_path=\"xception.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edfc26c-9384-4288-b7e0-41e5a5c94bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_xception.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e322bd-b8e4-46ba-ba93-e3fe300c8cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_xception = pd.DataFrame(history_xception.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a58a0e-7678-4d48-9604-beca9c32049b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_xception.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aced02-ba0b-4265-a14f-2e4d504c11c7",
   "metadata": {},
   "source": [
    "## DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8562d46-c7d7-4d15-9b87-2cdcd29fa7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to load image\n",
    "def image_loader_densenet121(path):\n",
    "    image = tf.io.read_file(path)                                # read image file as binary\n",
    "    image = tf.image.decode_png(image, channels=3)               # decode into image tensor\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)# converts to float32 data type and scaling the values appropriately before casting.\n",
    "    image = tf.image.resize(image, IMG_SIZE)                     # resize the image\n",
    "    image = keras.applications.densenet.preprocess_input(image)     # custom preprocessing for densenet121\n",
    "    label = tf.strings.split(path, os.path.sep)[-2]              # parse the class label from the file path\n",
    "    label = tf.strings.to_number(label, tf.int32)\n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039eb49-3ce4-436f-9fef-7996b78fbcb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_data = (\n",
    "    train_data.shuffle(len(train_paths))                           # shuffle data, optional as already did train_test_split in scikit-learn\n",
    "    .map(image_loader_densenet121, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .map(augmentation, num_parallel_calls=tf.data.AUTOTUNE)        # apply augmentation\n",
    "    .cache()                                                       # caching for fast read\n",
    "    .batch(batch_size=BATCH_SIZE)                                  # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                    # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices(val_paths)                    #no augmentation & shuffle required for test data as it is ground truth\n",
    "val_data = (\n",
    "    val_data.map(image_loader_densenet121, num_parallel_calls=tf.data.AUTOTUNE)   # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                           # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                             # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(train_paths)                 #no augmentation & shuffle required for test data as it is ground truth\n",
    "test_data = (\n",
    "    test_data.map(image_loader_densenet121, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                           # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                             # allows later elements to be prepared while the current element is being processed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc436782-a2bf-4168-a6b1-f1f22ba5f942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "densenet121 = keras.applications.DenseNet121(include_top=False,weights=\"imagenet\")\n",
    "densenet121.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d3a32-6acc-47ff-a388-2e740d957d28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_densenet121 = keras.models.Sequential(\n",
    "    [\n",
    "        densenet121,\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5832e3-05b3-4246-8f22-9afe41c12ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_densenet121.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58228574-846e-48f6-836d-178275b18a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_densenet121, model_densenet121 = compile_fit_model(model=model_densenet121, save_path=\"densenet152.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260036b-cd97-4d50-902a-5d5495a5ba5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_densenet121.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ddc592-7444-4d3c-a062-595a6664ed71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_densenet121 = pd.DataFrame(history_densenet121.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a0097-a0e8-424c-a613-ecbeda055a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_densenet121.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a826d7-1533-42cd-b30e-2053ee4de33f",
   "metadata": {},
   "source": [
    "## ResNet152V2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab2896-336a-432a-9331-e894d4051c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to load image\n",
    "def image_loader_resnet152(path):\n",
    "    image = tf.io.read_file(path)                                # read image file as binary\n",
    "    image = tf.image.decode_png(image, channels=3)               # decode into image tensor\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)# converts to float32 data type and scaling the values appropriately before casting.\n",
    "    image = tf.image.resize(image, IMG_SIZE)                     # resize the image\n",
    "    image = keras.applications.resnet_v2.preprocess_input(image)     # custom preprocessing for resnet152\n",
    "    label = tf.strings.split(path, os.path.sep)[-2]              # parse the class label from the file path\n",
    "    label = tf.strings.to_number(label, tf.int32)\n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aadfac-6581-4b4f-9eda-bdb1bda3301b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_data = (\n",
    "    train_data.shuffle(len(train_paths))                           # shuffle data, optional as already did train_test_split in scikit-learn\n",
    "    .map(image_loader_resnet152, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .map(augmentation, num_parallel_calls=tf.data.AUTOTUNE)        # apply augmentation\n",
    "    .cache()                                                       # caching for fast read\n",
    "    .batch(batch_size=BATCH_SIZE)                                  # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                    # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices(val_paths)                    #no augmentation & shuffle required for test data as it is ground truth\n",
    "val_data = (\n",
    "    val_data.map(image_loader_resnet152, num_parallel_calls=tf.data.AUTOTUNE)   # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                           # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                             # allows later elements to be prepared while the current element is being processed\n",
    ")\n",
    "\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(train_paths)                 #no augmentation & shuffle required for test data as it is ground truth\n",
    "test_data = (\n",
    "    test_data.map(image_loader_resnet152, num_parallel_calls=tf.data.AUTOTUNE)  # load the image\n",
    "    .batch(batch_size=BATCH_SIZE)                                           # batching the data\n",
    "    .prefetch(tf.data.AUTOTUNE)                                             # allows later elements to be prepared while the current element is being processed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e130e-f393-4d79-958d-01c48395354e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnet152 = keras.applications.ResNet152V2(include_top=False,weights=\"imagenet\")\n",
    "resnet152.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6397efb-0d77-4d7d-b995-0e8dd8d2c2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_resnet152 = keras.models.Sequential(\n",
    "    [\n",
    "        resnet152,\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22e46f-a6d8-4df1-95ca-a44ac0da26f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_resnet152.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa8c0b-9813-4191-9fb2-9c6a96b88cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_resnet152, model_resnet152 = compile_fit_model(model=model_resnet152, save_path=\"resnet152.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef7d3e2-eeec-43f2-bce9-f00b79253b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_resnet152.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34bdb9c-120c-418f-9174-05a2cc006c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_resnet152 = pd.DataFrame(history_resnet152.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3696b663-09cc-4bb2-a130-68801992a0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_resnet152.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceeb50e-f667-410e-a613-af7de6bea974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
